{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Árvores de Decisão\n",
    "\n",
    "Nas duas primeiras partes do nosso tutorial apresentamos uma introdução sobre aprendizagem supervisionado. Para ilustrar essa introdução, exploramos dois algoritmos (1) k-NN e (2) Regressão Linear. O primeiro é voltado para o problema de classificação e o segundo para o de regressão. \n",
    "\n",
    "Na aula de hoje vamos explorar maos o problema de classificação. Para isso, vamos trabalhar com um outro método de classificação: as árvores de decisão. \n",
    "\n",
    "Nas árvores de decisão, o problema de aprendizado de máquina é visto com um problema de busca num espaço possíveis soluções. Este método faz uso da estratégia dividir para conquistar para resolver o problema. A idéia básica é dividir um problema em problemas mais simples, aos quais são aplicadas, recursivamente, a mesma estratégia anterior. As soluções dos subproblemas podem ser combinados, na forma de uma árvore, para produzir uma solução do problema complexo. A força dessa proposta vem da capacidade de dividir o espaço de instâncias em subespaços e cda subespaço é ajustado usando diferentes modelos. Essa é a idéia básica por trás dos principais algoritmos de ávore de decisão, tais como: ID3, ASSITANT, CART, C4.5.\n",
    "\n",
    "Uma árvore de decisão é um grafo acíclico direcionado em que cada nó ou é um nó de divisão, com dois ou mais sucessores, ou um nó folha. A imagem a seguir mostra um exemplo de árvore de decisão e as regiões de decisão dentro do espaço de soluções definidos pelos atributos $x_1$ e $x_2$.\n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/u/25405260/d2l/material_ia/print_arvores_decisao.png\" width=\"800\">\n",
    "\n",
    "Cada nó da árvore corresponde a uma região no espaço de decisão que foi definido pelos atributos. É importante ressaltar que as regiões nesse espaço são mutuamente excludentes, e a reunião delas compõe todo o espaço definido pelos atributos. Vale observar que a árvore de decisão consegue abranger todo o espaço de instâncias. Isso implica que uma árvore de decisão é capaz de fazer predição para qualquer exemplo de entrada.\n",
    "\n",
    "## Algoritmo para construção da árvore de decisão\n",
    "\n",
    "O algoritmo para a construção da árvore de decisão consiste em escolher os atributos que melhor separam os dados. O ideal é que o primeiro atributo seja aquele que quando selecionado permita já separar um bom grupo de instâncias em uma das classes. \n",
    "\n",
    "Essa informação é chamada de **ganho de informação (GI)**. O GI mede a efetividade de um atributo em classificar um conjunto de treinamento. Em outras palavras, permite avaliar o quão bom um atributo é para classificar um conjunto de treinamento.\n",
    "\n",
    "O Ganho de Informação é dado por: \n",
    "\n",
    "$GI(S,A) = E(S) - \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)}$, \n",
    "\n",
    "onde E é a entropia dada por: \n",
    "\n",
    "$E = \\sum_{i}^{c}{-p_i\\log_2{p_i}}$\n",
    "\n",
    "A entropia ela mede o nível de certeza que temos sobre um determinado evento.\n",
    "\n",
    "Para ilustrar considere um evento qualquer que possui 14 exemplos. Destes exemplos 9 são positivos e 5 são negativos. A entropia desse conjunto é dada por:\n",
    "\n",
    "$E(S) = -\\frac{9}{14}\\log_2{\\frac{9}{14}} - \\frac{5}{14}\\log_2{\\frac{5}{14}} = 0.94$\n",
    "\n",
    "E se tivéssemos [7+, 7-]:\n",
    "\n",
    "$E(S) = -\\frac{7}{14}\\log_2{\\frac{7}{14}} - \\frac{7}{14}\\log_2{\\frac{7}{14}} = 0.999... \\approx 1$\n",
    "\n",
    "E para [0+,14-] ou [14+, 0-]:\n",
    "\n",
    "$E(S) = -\\frac{14}{14}\\log_2{\\frac{14}{14}} = 0$\n",
    "\n",
    "O cálculo do GI está relacionado com a Entropia. Na verdade, GI é a redução da entropia, causada pelo particionamento de exemplos de acordo com este atributo. Quanto maior a **redução da entropia** melhor o atributo. \n",
    "\n",
    "Vamos considerar o seguinte exemplo:\n",
    "\n",
    "Dado um conjunto de treinamento S contendo o atributo Vento (que pode receber dois Valores: Forte ou Fraco). Considere também que S possui 9 instâncias positivas e 5 instâncias negativas (classe para classificação). Considere também que 6 dos exemplos positivos e 2 exemplos dos negativos são associados a vento Fraco. Além disso, 3 exemplos negativos e 3 exemplos positivos estão associados a vento Forte. \n",
    "\n",
    "Pretende-se calcular o ganho de informação ao selecionar o valor atributo Vento para a raiz de uma árvore de decisão.\n",
    "\n",
    "**Cálculo**\n",
    "\n",
    "O conjunto S está dividido da seguinte forma: $S = [9+, 5-]$ e a divisão de acordo com o atributo é dada por:\n",
    "\n",
    "$S_{fraco} \\leftarrow [6+, 2-]$\n",
    "\n",
    "$S_{forte} \\leftarrow [3+, 3-]$\n",
    "\n",
    "Sabendo que o cálculo do GI é dado por: \n",
    "\n",
    "$GI(S,A) = E(S) - \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)}$, \n",
    "\n",
    "onde S é o conjunto de treinamento que vai ser dividido e A é o atributo a ser considerado. \n",
    "\n",
    "O primeiro passo é calcular E(S).\n",
    "\n",
    "$E(S) = -\\frac{9}{14}\\log_2{\\frac{9}{14}} - \\frac{5}{14}\\log_2{\\frac{5}{14}} = 0.940$\n",
    "\n",
    "Agora vamos trabalhar com os atributos: \n",
    "\n",
    "O atributo Vento possui dois valores: Forte e Fraco. Devemos calcular a entropia para cada um desses atributos: \n",
    "\n",
    "$E(S_{fraco}) = -\\frac{2}{8}\\log_2{\\frac{2}{8}} - \\frac{6}{8}\\log_2{\\frac{6}{8}} = 0.811$\n",
    "\n",
    "$E(S_{forte}) = -\\frac{3}{6}\\log_2{\\frac{3}{6}} - \\frac{3}{6}\\log_2{\\frac{3}{6}} = 1$\n",
    "\n",
    "Com isso podemos calcular: \n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)}$\n",
    "\n",
    "$- \\frac{8}{14}*0.811 - \\frac{6}{14}*1 = -0.892$\n",
    "\n",
    "Por fim, temos que  o Ganho de Informação é: \n",
    "\n",
    "$GI(S,A) = E(S) - \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = 0.940 - 0.892 = 0.048$\n",
    "\n",
    "Essa valor siginifica que selecionar esse atributo reduz muito pouco o nível de incerteza que tínhamos. Sendo assim, ele não é um atributo muito bom para ser selecionado.\n",
    "\n",
    "\n",
    "## Construindo uma árvore de decisão\n",
    "\n",
    "Vamos considerar o seguinte dataset:\n",
    "\n",
    "Exemplo retirado de: http://conteudo.icmc.usp.br/pessoas/mello/courses/scc5879-aula05.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Panorama</th>\n",
       "      <th>Temperatura</th>\n",
       "      <th>Umidade</th>\n",
       "      <th>Vento</th>\n",
       "      <th>Jogar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ensolarado</td>\n",
       "      <td>Quente</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Fraco</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ensolarado</td>\n",
       "      <td>Quente</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Forte</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nublado</td>\n",
       "      <td>Quente</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Fraco</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chuvoso</td>\n",
       "      <td>Intermediária</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Fraco</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chuvoso</td>\n",
       "      <td>Fria</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Fraco</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chuvoso</td>\n",
       "      <td>Fria</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Forte</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Nublado</td>\n",
       "      <td>Fria</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Forte</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ensolarado</td>\n",
       "      <td>Intermediária</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Fraco</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ensolarado</td>\n",
       "      <td>Fria</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Fraco</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chuvoso</td>\n",
       "      <td>Intermediária</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Fraco</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ensolarado</td>\n",
       "      <td>Intermediária</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Forte</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Nublado</td>\n",
       "      <td>Intermediária</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Forte</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Nublado</td>\n",
       "      <td>Quente</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Fraco</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chuvoso</td>\n",
       "      <td>Intermediária</td>\n",
       "      <td>Alta</td>\n",
       "      <td>Forte</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Panorama    Temperatura Umidade  Vento Jogar\n",
       "0   Ensolarado         Quente    Alta  Fraco   Não\n",
       "1   Ensolarado         Quente    Alta  Forte   Não\n",
       "2      Nublado         Quente    Alta  Fraco   Sim\n",
       "3      Chuvoso  Intermediária    Alta  Fraco   Sim\n",
       "4      Chuvoso           Fria  Normal  Fraco   Sim\n",
       "5      Chuvoso           Fria  Normal  Forte   Não\n",
       "6      Nublado           Fria  Normal  Forte   Sim\n",
       "7   Ensolarado  Intermediária    Alta  Fraco   Não\n",
       "8   Ensolarado           Fria  Normal  Fraco   Sim\n",
       "9      Chuvoso  Intermediária  Normal  Fraco   Sim\n",
       "10  Ensolarado  Intermediária  Normal  Forte   Sim\n",
       "11     Nublado  Intermediária    Alta  Forte   Sim\n",
       "12     Nublado         Quente  Normal  Fraco   Sim\n",
       "13     Chuvoso  Intermediária    Alta  Forte   Não"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('https://dl.dropboxusercontent.com/u/25405260/d2l/material_ia/exemplo_jogar.csv')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse dataset temos 4 parâmetros: (1) Panorama, (2) Temperatura, (3) Umidade e (4) Vento. A classe é o atributo *Jogar*. Para construir uma árvore de decisão o primeiro passo é escolher qual atributo será colocado na raiz da árvore. Dentre os atribuitos, o ideal é que seja escolhido sempre aquele que possui o maior ganho de informação. Vamos calcular GI para cada um dos atributos.\n",
    "\n",
    "**Atributo Vento [Forte, Fraco]**\n",
    "\n",
    "O GI de informação do atributo vento já foi calculado no exemplo anterior. O valor dele é **0.048**. Já sabemos que ele não é um bom atributo, mas só descartamos a escolha deste quando comporarmos o seu valor com o GI dos demais atributos.\n",
    "\n",
    "**Atributo Panorama [Ensolarado, Nublado, Chuvoso]**\n",
    "\n",
    "O atributo panorama está dividido da seguinte forma na base de treinamento: \n",
    "\n",
    "* Ensolarado: $\\frac{5}{14}$ onde $[2+, 3-]$ \n",
    "\n",
    "\n",
    "* Nublado: $\\frac{4}{14}$ onde $[4+, 0-]$\n",
    "\n",
    "\n",
    "* Chuvoso: $\\frac{5}{14}$ onde $[3+, 2-]$ \n",
    "\n",
    "Vamos calcular:\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{5}{14}*E(S_{Ensolarado}) - \\frac{4}{14}*E(S_{Nublado}) - \n",
    "\\frac{5}{14}*E(S_{Chuvoso})$\n",
    "\n",
    "Calculando a entropia de cada atributo temos:\n",
    "\n",
    "$E(S_{Ensolarado}) = - \\frac{2}{5}*log_2{\\frac{2}{5}} - \\frac{3}{5}*log_2{\\frac{3}{5}} = 0.971$\n",
    "\n",
    "$E(S_{Nublado}) = - \\frac{4}{4}*log_2{\\frac{4}{4}} - \\frac{0}{4}*log_2{\\frac{0}{4}} = 0$\n",
    "\n",
    "$E(S_{Chuvoso}) = - \\frac{3}{5}*log_2{\\frac{3}{5}} - \\frac{2}{5}*log_2{\\frac{2}{5}} = 0.971$\n",
    "\n",
    "Agora podemos calcular:\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{5}{14}*E(S_{Ensolarado}) - \\frac{4}{14}*E(S_{Nublado}) - \n",
    "\\frac{5}{14}*E(S_{Chuvoso})$\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{5}{14}*0.971 - \\frac{4}{14}*0 - \\frac{5}{14}*0.971 = -0.693$\n",
    "\n",
    "Por fim, temos que o GI de informação para o atributo Panorama é:\n",
    "\n",
    "$GI(S,A) = E(S) - \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)}$\n",
    "\n",
    "$GI(S,A) = 0.940 - 0.693 = 0.247$\n",
    "\n",
    "**Até o momento, temos: **\n",
    "\n",
    "$GI(Vento) = 0.048$\n",
    "\n",
    "$GI(Panorama) = 0.247$\n",
    "\n",
    "E o atributo **temperatura**?\n",
    "\n",
    "E o atributo **umidade**?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** O Atributo Umidade [Alta, Normal] **\n",
    "\n",
    "O atributo umidade está dividido da seguinte forma na base de treinamento: \n",
    "\n",
    "* Alta: $\\frac{7}{14}$ onde $[3+, 4-]$ \n",
    "\n",
    "\n",
    "* Normal: $\\frac{7}{14}$ onde $[6+, 1-]$\n",
    "\n",
    "\n",
    "Vamos calcular:\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{7}{14}*E(S_{Alta}) - \\frac{7}{14}*E(S_{Normal})$\n",
    "\n",
    "Calculando a entropia de cada atributo temos:\n",
    "\n",
    "$E(S_{Alta}) = - \\frac{3}{7}*log_2{\\frac{3}{7}} - \\frac{4}{7}*log_2{\\frac{4}{7}} = 0.985$\n",
    "\n",
    "$E(S_{Normal}) = - \\frac{6}{7}*log_2{\\frac{6}{7}} - \\frac{1}{7}*log_2{\\frac{1}{7}} = 0.591$\n",
    "\n",
    "\n",
    "Agora podemos calcular:\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{7}{14}*E(S_{Alta}) - \\frac{7}{14}*E(S_{Normal})$\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{7}{14}*0.985 - \\frac{7}{14}*0.591 = -0.788$\n",
    "\n",
    "Por fim, temos que o GI de informação para o atributo Umidade é:\n",
    "\n",
    "$GI(S,A) = E(S) - \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)}$\n",
    "\n",
    "$GI(S,A) = 0.940 - 0.788 = 0.152$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atributo Temperatura [Quente, Intermediária, Fria]**\n",
    "\n",
    "O atributo Temperatura está dividido da seguinte forma na base de treinamento: \n",
    "\n",
    "* Quente: $\\frac{4}{14}$ onde $[2+, 2-]$ \n",
    "\n",
    "\n",
    "* Intermediária: $\\frac{6}{14}$ onde $[4+, 2-]$\n",
    "\n",
    "\n",
    "* Fria: $\\frac{4}{14}$ onde $[3+, 1-]$ \n",
    "\n",
    "Vamos calcular:\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{4}{14}*E(S_{Quente}) - \\frac{6}{14}*E(S_{Intermediaria}) - \n",
    "\\frac{4}{14}*E(S_{Fria})$\n",
    "\n",
    "Calculando a entropia de cada atributo temos:\n",
    "\n",
    "$E(S_{Quente}) = - \\frac{2}{4}*log_2{\\frac{2}{4}} - \\frac{2}{4}*log_2{\\frac{2}{4}} = 1$\n",
    "\n",
    "$E(S_{Nublado}) = - \\frac{4}{6}*log_2{\\frac{4}{6}} - \\frac{2}{6}*log_2{\\frac{2}{6}} = 0.918$\n",
    "\n",
    "$E(S_{Chuvoso}) = - \\frac{3}{4}*log_2{\\frac{3}{4}} - \\frac{1}{4}*log_2{\\frac{1}{4}} = 0.811$\n",
    "\n",
    "Agora podemos calcular:\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{4}{14}*E(S_{Quente}) - \\frac{6}{14}*E(S_{Intermediaria}) - \n",
    "\\frac{4}{14}*E(S_{Fria})$\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{4}{14}*1 - \\frac{6}{14}*0.918 - \\frac{4}{14}*0.811 = -0.910$\n",
    "\n",
    "Por fim, temos que o GI de informação para o atributo Panorama é:\n",
    "\n",
    "$GI(S,A) = E(S) - \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)}$\n",
    "\n",
    "$GI(S,A) = 0.940 - 0.910 = 0.030$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessa forma, já temos a análise dos 4 atributos: \n",
    "\n",
    "$GI(S, Panorama) = 0.247$\n",
    "\n",
    "$GI(S, Umidade) = 0.152$\n",
    "\n",
    "$GI(S, Vento) = 0.048$\n",
    "\n",
    "$GI(S, Temperatura) = 0.03$\n",
    "\n",
    "Dos 4 atributos, devemos selecionar aquele que proporciona um maior ganho de informação. Neste caso, escolhemos o atributo **Panorama**. Ele é que deve ser a raiz da árvore. \n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/u/25405260/d2l/material_ia/arvoredecisao_01.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que com a escolha desse atributo já conseguimos classificar um conjunto de dados do treinamento. Se o panorama for Nublado, sempre jogará tênis. No entanto, ainda não temos certeza quando o panorama for ensolarado ou chuvoso. Nestes casos, devemos analisar novamente os atributos do conjunto de treinamento para decidir qual atributo devemos escolher para o nó quando for ensolarado e quando for chuvoso. Para este cálculo, o atributo Panorama não entra na computação do Ganho de Informação.\n",
    "\n",
    "O processo de cálculo é o mesmo. No entanto, seu conjunto *S* muda. *S* passa ser agora, no caso de ensolarado, $D1, D2, D8, D9, D11$ que são divididos em $[2+, 3-]$.\n",
    "\n",
    "O primeiro passo é calcular a entropia de S ($E(S)$):\n",
    "\n",
    "$E = \\sum_{i}^{c}{-p_i\\log_2{p_i}} = -\\frac{2}{5}*\\log_2{\\frac{2}{5}} - \\frac{3}{5}*\\log_2{\\frac{3}{5}} = 0.971$\n",
    "\n",
    "Com o valor da Entropia de $S$, calculamos o $GI$ para cada um dos atributos restantes: Umidade, Temperatura e Vento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Atributo Umidade **\n",
    "\n",
    "** O Atributo Umidade [Alta, Normal] **\n",
    "\n",
    "O atributo umidade está dividido da seguinte forma na base de treinamento: \n",
    "\n",
    "* Alta: $\\frac{3}{5}$ onde $[0+, 3-]$ \n",
    "\n",
    "\n",
    "* Normal: $\\frac{2}{5}$ onde $[2+, 0-]$\n",
    "\n",
    "\n",
    "Vamos calcular:\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{3}{5}*E(S_{Alta}) - \\frac{2}{5}*E(S_{Normal})$\n",
    "\n",
    "Calculando a entropia de cada atributo temos:\n",
    "\n",
    "$E(S_{Alta}) = - \\frac{0}{3}*log_2{\\frac{0}{3}} - \\frac{3}{3}*log_2{\\frac{3}{3}} = 0$\n",
    "\n",
    "$E(S_{Normal}) = - \\frac{2}{2}*log_2{\\frac{2}{2}} - \\frac{0}{2}*log_2{\\frac{0}{2}} = 0$\n",
    "\n",
    "\n",
    "Agora podemos calcular:\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{3}{5}*E(S_{Alta}) - \\frac{3}{5}*E(S_{Normal})$\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{3}{5}*0 - \\frac{3}{5}*0 = 0$\n",
    "\n",
    "Por fim, temos que o GI de informação para o atributo Umidade é:\n",
    "\n",
    "$GI(S,A) = E(S) - \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)}$\n",
    "\n",
    "$GI(S,A) = 0.971 - 0 = 0.971$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atributo Temperatura [Quente, Intermediária, Fria]**\n",
    "\n",
    "O atributo Temperatura está dividido da seguinte forma na base de treinamento: \n",
    "\n",
    "* Quente: $\\frac{2}{5}$ onde $[0+, 2-]$ \n",
    "\n",
    "\n",
    "* Intermediária: $\\frac{2}{5}$ onde $[1+, 1-]$\n",
    "\n",
    "\n",
    "* Fria: $\\frac{1}{5}$ onde $[1+, 0-]$ \n",
    "\n",
    "É fácil definir as entropiais individiuais:\n",
    "\n",
    "$E_(S_{Quente}) = 0$\n",
    "\n",
    "$E_(S_{Intermediaria}) = 1$\n",
    "\n",
    "$E_(S_{Fria}) = 0$\n",
    "\n",
    "Vamos calcular:\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{2}{5}*E(S_{Quente}) - \\frac{2}{5}*E(S_{Intermediaria}) - \n",
    "\\frac{1}{5}*E(S_{Fria})$\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{2}{5}*0 - \\frac{2}{5}*1 - \\frac{1}{5}*0 = -0.4$\n",
    "\n",
    "Por fim, temos que o GI de informação para o atributo Temperatura é:\n",
    "\n",
    "$GI(S,A) = E(S) - \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)}$\n",
    "\n",
    "$GI(S,A) = 0.971 - 0.4 = 0.571$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atributo Vento [Fraco, Forte]**\n",
    "\n",
    "O atributo Vento está dividido da seguinte forma na base de treinamento: \n",
    "\n",
    "* Fraco: $\\frac{3}{5}$ onde $[1+, 2-]$ \n",
    "\n",
    "\n",
    "* Forte: $\\frac{2}{5}$ onde $[1+, 1-]$\n",
    "\n",
    "É fácil definir as entropiais individiuais:\n",
    "\n",
    "$E_(S_{Fraco}) = 0.918$\n",
    "\n",
    "$E_(S_{Forte}) = 1$\n",
    "\n",
    "Vamos calcular:\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{3}{5}*E(S_{Quente}) - \\frac{2}{5}*E(S_{Intermediaria})$\n",
    "\n",
    "$- \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)} = -\\frac{3}{5}*0.918 - \\frac{2}{5}*1 = -0.951$\n",
    "\n",
    "Por fim, temos que o GI de informação para o atributo Vento é:\n",
    "\n",
    "$GI(S,A) = E(S) - \\sum_{v \\in Valores(A)}{\\frac{S_v}{S}E(S_v)}$\n",
    "\n",
    "$GI(S,A) = 0.971 - 0.950 = 0.020$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dessa forma, já temos a análise dos 3 atributos restantes: \n",
    "\n",
    "$GI(S, Umidade) = 0.971$\n",
    "\n",
    "$GI(S, Vento) = 0.571$\n",
    "\n",
    "$GI(S, Temperatura) = 0.020$\n",
    "\n",
    "Dos 3 atributos, devemos selecionar aquele que proporciona um maior ganho de informação. Neste caso, escolhemos o atributo **Umidade**. Ele é que deve ser o atributo quando ensolarado. \n",
    "\n",
    "<img src=\"https://dl.dropboxusercontent.com/u/25405260/d2l/material_ia/arvoredecisao_02.png\">\n",
    "\n",
    "E no caso do ramo **Chuvoso**, como fica a separação? \n",
    "\n",
    "** Atividade: ** Aplicar o algoritmo visto no ramo chuvoso e determinar qual a próxima subdivisão da árvore. Relizar o processo até que todos os dados do treinamento tenham sido devidamente classificados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Panorama</th>\n",
       "      <th>Temperatura</th>\n",
       "      <th>Umidade</th>\n",
       "      <th>Vento</th>\n",
       "      <th>Jogar</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Não</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Panorama  Temperatura  Umidade  Vento Jogar\n",
       "0          1            2        0      1   Não\n",
       "1          1            2        0      0   Não\n",
       "2          2            2        0      1   Sim\n",
       "3          0            1        0      1   Sim\n",
       "4          0            0        1      1   Sim\n",
       "5          0            0        1      0   Não\n",
       "6          2            0        1      0   Sim\n",
       "7          1            1        0      1   Não\n",
       "8          1            0        1      1   Sim\n",
       "9          0            1        1      1   Sim\n",
       "10         1            1        1      0   Sim\n",
       "11         2            1        0      0   Sim\n",
       "12         2            2        1      1   Sim\n",
       "13         0            1        0      0   Não"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "le_ = preprocessing.LabelEncoder()\n",
    "\n",
    "data.Panorama = le_.fit_transform(data.Panorama)\n",
    "data.Temperatura = le_.fit_transform(data.Temperatura)\n",
    "data.Umidade = le_.fit_transform(data.Umidade)\n",
    "data.Vento = le_.fit_transform(data.Vento)\n",
    "\n",
    "X = data[feature_columns]\n",
    "y = data.Jogar\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "clf = clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Sim'], dtype=object)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[2, 0, 0, 0]]) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
